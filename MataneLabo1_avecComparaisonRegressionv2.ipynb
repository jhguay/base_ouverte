{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRvyxIKFM2fk4U15C8JGtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhguay/base_ouverte/blob/main/MataneLabo1_avecComparaisonRegressionv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des bibliothèques et de la base de données"
      ],
      "metadata": {
        "id": "Qt5NAZs-O6T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici je reprends l'exemple développé dans le cours **Vision artificielle et exploitation des ressources naturelles** du Cegep de Matane. L'exemple est construit à partir d'une base sur la loi de Kleiber expliquant le métabolisme par la masse."
      ],
      "metadata": {
        "id": "4yR72LcnIjEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques Python\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Lecture des données\n",
        "loi_kleiber_data = pd.read_csv(\"https://github.com/ClaudeCoulombe/VIARENA/blob/master/DATA/LoiDeKleiber.csv?raw=True\")\n",
        "print(loi_kleiber_data)\n",
        "print(\"Données lues\")\n",
        "\n",
        "loi_kleiber_data.info()\n",
        "loi_kleiber_data.sample(n=5,random_state=42)\n",
        "loi_kleiber_data['Masse'].max()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLnpfpiRPd5g",
        "outputId": "656efff9-fcd8-4c5b-ee2a-77ab48d25789"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 NomCommun                    Espece    Masse  Metabolisme  \\\n",
            "0                  Echidna    Tachiglossus aculeatus    2.500        302.0   \n",
            "1      Long-beaked echidna         Zaglossus bruijni   10.300        594.0   \n",
            "2                 Platypus  Ornithorhynchus anatinus    1.300        229.0   \n",
            "3                  Opossum  Lutreolina crassicaudata    0.812        196.0   \n",
            "4   South American opossum     Didelphis marsupialis    1.330        299.0   \n",
            "..                     ...                       ...      ...          ...   \n",
            "90           Rhesus monkey            Macaca mulatta    5.000        960.0   \n",
            "91               Orangutan           Pongo pygma eus  150.000      15500.0   \n",
            "92                 Gorilla           Gorilla gorilla  250.000      21000.0   \n",
            "93                  Gibbon             Hylobater lar    8.000       1510.0   \n",
            "94                   # Man              Homo sapiens   65.000       7560.0   \n",
            "\n",
            "    DureeDeVie  \n",
            "0         14.0  \n",
            "1         20.0  \n",
            "2          9.0  \n",
            "3          5.0  \n",
            "4          6.0  \n",
            "..         ...  \n",
            "90        25.0  \n",
            "91        45.0  \n",
            "92        45.0  \n",
            "93        25.0  \n",
            "94        75.0  \n",
            "\n",
            "[95 rows x 5 columns]\n",
            "Données lues\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95 entries, 0 to 94\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   NomCommun    95 non-null     object \n",
            " 1   Espece       95 non-null     object \n",
            " 2   Masse        95 non-null     float64\n",
            " 3   Metabolisme  95 non-null     float64\n",
            " 4   DureeDeVie   95 non-null     float64\n",
            "dtypes: float64(3), object(2)\n",
            "memory usage: 3.8+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000.0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement selon la méthode classique de la régression"
      ],
      "metadata": {
        "id": "VZ5aGZ4YPrgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from patsy import dmatrices\n",
        "y,x=dmatrices('Metabolisme ~ Masse', data=loi_kleiber_data,return_type='dataframe')\n",
        "mod=sm.OLS(y,x)\n",
        "res=mod.fit()\n",
        "print(res.summary())\n",
        "\n",
        "#Application de l'équation de régresion\n",
        "print(\"--------------------------------------------------------------------------------------------------------------\")\n",
        "masse=65\n",
        "predictionMetabolisme=1203.2019+(57.0268*masse)\n",
        "print(predictionMetabolisme)"
      ],
      "metadata": {
        "id": "tDBl9NYLPq0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574402ea-fccf-460a-beaf-81911f108084"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:            Metabolisme   R-squared:                       0.979\n",
            "Model:                            OLS   Adj. R-squared:                  0.979\n",
            "Method:                 Least Squares   F-statistic:                     4302.\n",
            "Date:                Fri, 21 Oct 2022   Prob (F-statistic):           1.15e-79\n",
            "Time:                        00:04:12   Log-Likelihood:                -887.05\n",
            "No. Observations:                  95   AIC:                             1778.\n",
            "Df Residuals:                      93   BIC:                             1783.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept   1203.2019    291.270      4.131      0.000     624.798    1781.606\n",
            "Masse         57.0268      0.869     65.586      0.000      55.300      58.753\n",
            "==============================================================================\n",
            "Omnibus:                       67.129   Durbin-Watson:                   1.127\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              296.470\n",
            "Skew:                           2.419   Prob(JB):                     4.19e-65\n",
            "Kurtosis:                      10.176   Cond. No.                         342.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "4909.9439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement selon la méthode propre à l'intelligence artificielle"
      ],
      "metadata": {
        "id": "7B41YRDfP255"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE=11\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "print(\"Germe aléatoire fixé\")\n",
        "\n",
        "#On isole les deux variables et on les normalise\n",
        "\n",
        "attribut_predictif = loi_kleiber_data['Masse'].values.reshape(-1, 1)\n",
        "normalisateur_attribut_predictif = StandardScaler()\n",
        "normalisateur_attribut_predictif.fit(attribut_predictif)\n",
        "attribut_predictif = normalisateur_attribut_predictif.transform(attribut_predictif)\n",
        "\n",
        "attribut_cible = loi_kleiber_data['Metabolisme'].values.reshape(-1, 1)\n",
        "normalisateur_attribut_cible = StandardScaler()\n",
        "normalisateur_attribut_cible.fit(attribut_cible)\n",
        "attribut_cible = normalisateur_attribut_cible.transform(attribut_cible)\n",
        "\n",
        "# Construction d'un réseau de neurones de typ percptron à trois couches: couche d'entrée, couche cachée, couche de sortie\n",
        "reseau_de_neurones = tf.keras.models.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1]),\n",
        "                                                 tf.keras.layers.Dense(units=10, activation='relu'),\n",
        "                                                 tf.keras.layers.Dense(units=1)])\n",
        "# Affichage de l'architecture du réseau\n",
        "print(\"Architecture du réseau de neurones:\")\n",
        "reseau_de_neurones.summary()\n",
        "\n",
        "#Compilation du réseau de neurones\n",
        "# optimiseur: Adam\n",
        "# taux d'apprentissage: 0.001\n",
        "# fonction d'erreur: erreur quadratique moyenne ('mean_squared_error') \n",
        "\n",
        "# Compilation du réseau de neurones - optimiseur: Adam, taux d'apprentissage: 0.001, fonction d'erreur: erreur quadratique moyenne (mean_squared_error) \n",
        "reseau_de_neurones.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='mean_squared_error')\n",
        "print(\"Réseau de neurones compilé\")\n",
        "\n",
        "# Entraînement du réseau sur les données: variable_explicative et variable_dependante, pendant 500 itérations ou époques\n",
        "traces = reseau_de_neurones.fit(attribut_predictif,attribut_cible,epochs=500,verbose=1)\n",
        "# Affichage de l'erreur à la fin de l'entraînement\n",
        "print(\"Erreur à la fin:\",traces.history['loss'][-1])"
      ],
      "metadata": {
        "id": "k1k0X2LeQ586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690a2413-2ace-4c64-b7a4-41896a3567fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Germe aléatoire fixé\n",
            "Architecture du réseau de neurones:\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Réseau de neurones compilé\n",
            "Epoch 1/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5169\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4939\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4811\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4698\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4499\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4323\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4234\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4073\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.3922\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3746\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3641\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3498\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3302\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3212\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.3099\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2913\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2798\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2688\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2625\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2484\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2351\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2211\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2133\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2026\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1956\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1804\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1735\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1626\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1548\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1484\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1400\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1337\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1230\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1157\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1114\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1032\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0971\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0934\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0855\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0822\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0749\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0722\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0661\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0614\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0589\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0536\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0513\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0467\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0450\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0409\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0376\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0360\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0339\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0317\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0290\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0266\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0257\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0237\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0219\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0196\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0185\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0175\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0165\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0155\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0145\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0137\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0134\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0125\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0121\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0117\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0113\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0108\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0104\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0100\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0098\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0097\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0094\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0092\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0090\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0089\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0087\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0086\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0085\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0084\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0083\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0083\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0082\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0081\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0081\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0081\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0080\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0080\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0080\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0079\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0079\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0079\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0079\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0079\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0079\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0078\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0078\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0078\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0078\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0078\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0078\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0078\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0077\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0077\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0077\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0076\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0077\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0076\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0076\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0076\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0076\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0076\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0076\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0076\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0076\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0076\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0076\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0076\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0076\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0076\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0076\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0076\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0075\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0075\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.0075\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0074\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0075\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0074\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0074\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0075\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0074\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0074\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Erreur à la fin: 0.007429633755236864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Évaluation du réseau de neuronnes avec des cas nouveaux"
      ],
      "metadata": {
        "id": "XUBIZGjURBC6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXpfYx-KnA09",
        "outputId": "7a7e43ca-05a4-4df5-b668-00ac4af971bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 104ms/step\n",
            "\n",
            "Animal: être humain , Masse: 65.0 , prédiction du métabolisme: 8268.58 , Vraie valeur du métabolisme: 7560.0 , écart en %: -9.37 %\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Être humain, Homo sapiens\n",
        "animal = \"être humain\"\n",
        "masse = 6.50E+01\n",
        "# Normalisation de la donnée d'entrée\n",
        "masse_normalisee = normalisateur_attribut_predictif.transform(np.array([masse]).reshape(-1, 1))\n",
        "vraie_valeur_metabolisme = 7.56E+03\n",
        "# Application du modèle en inférence ou prédiction de la variable dépendante et «dénormalisation» du résultat\n",
        "prediction_metabolisme = normalisateur_attribut_cible.inverse_transform(reseau_de_neurones.predict(masse_normalisee))[0][0]\n",
        "# Affichage de la prédiction, de la vraie valeur (mesurée) et de l'écart (ou erreur) en %\n",
        "print(\"\\nAnimal:\", animal,\n",
        "      \", Masse:\", masse,\n",
        "      \", prédiction du métabolisme:\", round(prediction_metabolisme,2),\n",
        "      \", Vraie valeur du métabolisme:\", vraie_valeur_metabolisme,\n",
        "      \", écart en %:\", round((vraie_valeur_metabolisme-prediction_metabolisme)/vraie_valeur_metabolisme*100,2),\"%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def obtientPredictionDuRN(masse=65):\n",
        "  masse_normalisee = normalisateur_attribut_predictif.transform(np.array([masse]).reshape(-1, 1))\n",
        "  prediction_metabolisme = normalisateur_attribut_cible.inverse_transform(reseau_de_neurones.predict(masse_normalisee))[0][0]\n",
        "  return round(prediction_metabolisme,1)\n",
        "\n",
        "def obtientPredictionDuR(masse=65):\n",
        "  predictionRegressionMetabolisme=1203.2019+(57.0268*masse)\n",
        "  return round(predictionRegressionMetabolisme,1)\n",
        "\n",
        "\n",
        "listeResultatsRN=[] #liste des résultats selon le modèle IA\n",
        "for i in range(2,3000,20):\n",
        "  #print(obtientPredictionDuRN(i))\n",
        "  listeResultatsRN.append(obtientPredictionDuRN(i))\n",
        "\n",
        "listeResultatsR=[] #liste des résultats selon le modèle de la régression classique\n",
        "for i in range(2,3000,20):\n",
        "  predictionMetabolisme=1203.2019+(57.0268*masse)\n",
        "  listeResultatsR.append(1203.2019+(57.0268*i))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvTzQbL1TNzJ",
        "outputId": "eda5f770-5282-4ca0-fb40-09abdc8c9a75"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculErreur(valeurReelle=2,estimation=1):\n",
        "  resultat=(valeurReelle-estimation)/valeurReelle*100\n",
        "\n",
        "  return round(resultat,1)\n",
        "\n",
        "listeDesMasses=list(loi_kleiber_data[\"Masse\"])\n",
        "\n",
        "\n",
        "print(listeDesMasses)\n",
        "for i in range(0, len(listeDesMasses)):\n",
        "  print(\"Nom \"+str(loi_kleiber_data['NomCommun'][i])+\n",
        "      \" Masse: \"+str(loi_kleiber_data['Masse'][i])+\n",
        "        \" Metabolisme: \"+str(loi_kleiber_data['Metabolisme'][i])+\n",
        "        \" R: \"+str(obtientPredictionDuR(loi_kleiber_data['Masse'][i]))+\n",
        "        \" RN: \"+str(obtientPredictionDuRN(loi_kleiber_data['Masse'][i]))+\n",
        "        \" Erreur R (%): \"+str(calculErreur(loi_kleiber_data['Metabolisme'][i],obtientPredictionDuR(loi_kleiber_data['Masse'][i])))+\n",
        "        \" Erreur RN (%):\"+str(calculErreur(loi_kleiber_data['Metabolisme'][i],obtientPredictionDuRN(loi_kleiber_data['Masse'][i]))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UREp3XN08vV",
        "outputId": "8e3c25c2-77e9-4b78-c38e-720778685c1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.5, 10.3, 1.3, 0.812, 1.33, 3.26, 0.0141, 0.00365, 0.0085, 0.089, 1.0, 0.645, 0.015, 0.013, 5.05, 1.98, 4.69, 40.0, 4.8, 3.79, 3.32, 2.73, 4.22, 0.021, 0.362, 0.0438, 0.0481, 0.0098, 0.028, 0.0195, 0.021, 0.321, 0.139, 0.187, 0.172, 0.842, 0.0115, 0.0395, 0.0215, 0.0455, 0.0222, 0.0036, 0.005, 0.494, 6.78, 0.75, 0.5, 2.65, 0.076, 0.109, 0.132, 0.187, 0.161, 2.5, 1.58, 2.3, 3.0, 3.36, 0.702, 32.0, 407.0, 3000.0, 19.0, 58.0, 400.0, 49.0, 65.0, 420.0, 40.0, 140.0, 20.2, 10.0, 12.7, 11.1, 40.0, 5.01, 10.0, 14.0, 18.0, 3.0, 0.66, 26.0, 170.0, 1000.0, 0.029, 0.022, 0.148, 0.057, 0.598, 45.0, 5.0, 150.0, 250.0, 8.0, 65.0]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Nom Echidna Masse: 2.5 Metabolisme: 302.0 R: 1345.8 RN: 479.1 Erreur R (%): -345.6 Erreur RN (%):-58.6\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Nom Long-beaked echidna Masse: 10.3 Metabolisme: 594.0 R: 1790.6 RN: 1458.4 Erreur R (%): -201.4 Erreur RN (%):-145.5\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Platypus Masse: 1.3 Metabolisme: 229.0 R: 1277.3 RN: 328.5 Erreur R (%): -457.8 Erreur RN (%):-43.4\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Nom Opossum Masse: 0.812 Metabolisme: 196.0 R: 1249.5 RN: 267.2 Erreur R (%): -537.5 Erreur RN (%):-36.3\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom South American opossum Masse: 1.33 Metabolisme: 299.0 R: 1279.0 RN: 332.2 Erreur R (%): -327.8 Erreur RN (%):-11.1\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Nom Virginia opossum Masse: 3.26 Metabolisme: 519.0 R: 1389.1 RN: 574.5 Erreur R (%): -167.6 Erreur RN (%):-10.7\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Australian marsupial Masse: 0.0141 Metabolisme: 9.0 R: 1204.0 RN: 167.0 Erreur R (%): -13277.8 Erreur RN (%):-1755.6\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Marsupial   Masse: 0.00365 Metabolisme: 17.6 R: 1203.4 RN: 165.7 Erreur R (%): -6737.5 Erreur RN (%):-841.5\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Nom Marsupial Masse: 0.0085 Metabolisme: 5.17 R: 1203.7 RN: 166.3 Erreur R (%): -23182.4 Erreur RN (%):-3116.6\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Marsupial rat Masse: 0.089 Metabolisme: 37.4 R: 1208.3 RN: 176.4 Erreur R (%): -3130.7 Erreur RN (%):-371.7\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Nom Bandicoot Masse: 1.0 Metabolisme: 201.0 R: 1260.2 RN: 290.8 Erreur R (%): -527.0 Erreur RN (%):-44.7\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Long-nosed bandicoot Masse: 0.645 Metabolisme: 153.0 R: 1240.0 RN: 246.2 Erreur R (%): -710.5 Erreur RN (%):-60.9\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Fat-tailed dunnart Masse: 0.015 Metabolisme: 9.64 R: 1204.1 RN: 167.1 Erreur R (%): -12390.7 Erreur RN (%):-1633.4\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Australian marsupial Masse: 0.013 Metabolisme: 13.7 R: 1203.9 RN: 166.9 Erreur R (%): -8687.6 Erreur RN (%):-1118.2\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Tasmanian devil Masse: 5.05 Metabolisme: 628.0 R: 1491.2 RN: 799.2 Erreur R (%): -137.5 Erreur RN (%):-27.3\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Brushtail possum Masse: 1.98 Metabolisme: 306.0 R: 1316.1 RN: 413.8 Erreur R (%): -330.1 Erreur RN (%):-35.2\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Kangaroo Masse: 4.69 Metabolisme: 694.0 R: 1470.7 RN: 754.0 Erreur R (%): -111.9 Erreur RN (%):-8.6\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Red kangaroo Masse: 40.0 Metabolisme: 4000.0 R: 3484.3 RN: 5187.0 Erreur R (%): 12.9 Erreur RN (%):-29.7\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Tammar wallaby Masse: 4.8 Metabolisme: 671.0 R: 1476.9 RN: 767.9 Erreur R (%): -120.1 Erreur RN (%):-14.4\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Sloth Masse: 3.79 Metabolisme: 331.0 R: 1419.3 RN: 641.1 Erreur R (%): -328.8 Erreur RN (%):-93.7\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Armadillo Masse: 3.32 Metabolisme: 384.0 R: 1392.5 RN: 582.1 Erreur R (%): -262.6 Erreur RN (%):-51.6\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Pangolin Masse: 2.73 Metabolisme: 440.0 R: 1358.9 RN: 508.0 Erreur R (%): -208.8 Erreur RN (%):-15.5\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Scaly anteater Masse: 4.22 Metabolisme: 529.0 R: 1443.9 RN: 695.0 Erreur R (%): -172.9 Erreur RN (%):-31.4\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Short-tailed shrew Masse: 0.021 Metabolisme: 25.3 R: 1204.4 RN: 167.9 Erreur R (%): -4660.5 Erreur RN (%):-563.6\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Hamster Masse: 0.362 Metabolisme: 112.0 R: 1223.8 RN: 210.7 Erreur R (%): -992.7 Erreur RN (%):-88.1\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Nom Spiny pocket mouse Masse: 0.0438 Metabolisme: 22.5 R: 1205.7 RN: 170.7 Erreur R (%): -5258.7 Erreur RN (%):-658.7\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Mexican mouse Masse: 0.0481 Metabolisme: 26.0 R: 1205.9 RN: 171.3 Erreur R (%): -4538.1 Erreur RN (%):-558.8\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Nom Mouse Masse: 0.0098 Metabolisme: 18.0 R: 1203.8 RN: 166.5 Erreur R (%): -6587.8 Erreur RN (%):-825.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Mouse Masse: 0.028 Metabolisme: 22.0 R: 1204.8 RN: 168.8 Erreur R (%): -5376.4 Erreur RN (%):-667.3\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Nom Golden mouse Masse: 0.0195 Metabolisme: 23.8 R: 1204.3 RN: 167.7 Erreur R (%): -4960.1 Erreur RN (%):-604.6\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Mouse Masse: 0.021 Metabolisme: 20.9 R: 1204.4 RN: 167.9 Erreur R (%): -5662.7 Erreur RN (%):-703.3\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Woodrat Masse: 0.321 Metabolisme: 121.0 R: 1221.5 RN: 205.5 Erreur R (%): -909.5 Erreur RN (%):-69.8\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Woodrat Masse: 0.139 Metabolisme: 48.2 R: 1211.1 RN: 182.7 Erreur R (%): -2412.7 Erreur RN (%):-279.0\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Woodrat Masse: 0.187 Metabolisme: 71.3 R: 1213.9 RN: 188.7 Erreur R (%): -1602.5 Erreur RN (%):-164.7\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Woodrat Masse: 0.172 Metabolisme: 61.4 R: 1213.0 RN: 186.8 Erreur R (%): -1875.6 Erreur RN (%):-204.2\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Musk rat Masse: 0.842 Metabolisme: 333.0 R: 1251.2 RN: 271.0 Erreur R (%): -275.7 Erreur RN (%):18.6\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Pocket mouse Masse: 0.0115 Metabolisme: 11.4 R: 1203.9 RN: 166.7 Erreur R (%): -10460.5 Erreur RN (%):-1362.3\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Mouse Masse: 0.0395 Metabolisme: 23.8 R: 1205.5 RN: 170.2 Erreur R (%): -4965.1 Erreur RN (%):-615.1\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Rodent Masse: 0.0215 Metabolisme: 15.4 R: 1204.4 RN: 167.9 Erreur R (%): -7720.8 Erreur RN (%):-990.3\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Nom Rodent Masse: 0.0455 Metabolisme: 22.6 R: 1205.8 RN: 171.0 Erreur R (%): -5235.4 Erreur RN (%):-656.6\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom White-footed mouse Masse: 0.0222 Metabolisme: 26.8 R: 1204.5 RN: 168.0 Erreur R (%): -4394.4 Erreur RN (%):-526.9\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Shrew Masse: 0.0036 Metabolisme: 15.0 R: 1203.4 RN: 165.7 Erreur R (%): -7922.7 Erreur RN (%):-1004.7\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Nom Common shrew Masse: 0.005 Metabolisme: 17.6 R: 1203.5 RN: 165.9 Erreur R (%): -6738.1 Erreur RN (%):-842.6\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Nom Chinchilla Masse: 0.494 Metabolisme: 112.0 R: 1231.4 RN: 227.3 Erreur R (%): -999.5 Erreur RN (%):-102.9\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Nom Viscacha Masse: 6.78 Metabolisme: 916.0 R: 1589.8 RN: 1016.4 Erreur R (%): -73.6 Erreur RN (%):-11.0\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Rodent Masse: 0.75 Metabolisme: 193.0 R: 1246.0 RN: 259.4 Erreur R (%): -545.6 Erreur RN (%):-34.4\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Guinea pig Masse: 0.5 Metabolisme: 192.0 R: 1231.7 RN: 228.0 Erreur R (%): -541.5 Erreur RN (%):-18.8\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Marmot Masse: 2.65 Metabolisme: 320.0 R: 1354.3 RN: 497.9 Erreur R (%): -323.2 Erreur RN (%):-55.6\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom Rat Masse: 0.076 Metabolisme: 40.7 R: 1207.5 RN: 174.8 Erreur R (%): -2866.8 Erreur RN (%):-329.5\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Nom Rat Masse: 0.109 Metabolisme: 30.5 R: 1209.4 RN: 178.9 Erreur R (%): -3865.2 Erreur RN (%):-486.6\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Nom Rat Masse: 0.132 Metabolisme: 80.9 R: 1210.7 RN: 181.8 Erreur R (%): -1396.5 Erreur RN (%):-124.7\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Rat Masse: 0.187 Metabolisme: 51.4 R: 1213.9 RN: 188.7 Erreur R (%): -2261.7 Erreur RN (%):-267.1\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Cotton rat Masse: 0.161 Metabolisme: 168.0 R: 1212.4 RN: 185.5 Erreur R (%): -621.7 Erreur RN (%):-10.4\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Brown hare Masse: 2.5 Metabolisme: 528.0 R: 1345.8 RN: 479.1 Erreur R (%): -154.9 Erreur RN (%):9.3\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Snowshoe hare Masse: 1.58 Metabolisme: 686.0 R: 1293.3 RN: 363.6 Erreur R (%): -88.5 Erreur RN (%):47.0\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Nom Jack Rabbit Masse: 2.3 Metabolisme: 623.0 R: 1334.4 RN: 454.0 Erreur R (%): -114.2 Erreur RN (%):27.1\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Mountain hare Masse: 3.0 Metabolisme: 522.0 R: 1374.3 RN: 541.9 Erreur R (%): -163.3 Erreur RN (%):-3.8\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Hare Masse: 3.36 Metabolisme: 730.0 R: 1394.8 RN: 587.1 Erreur R (%): -91.1 Erreur RN (%):19.6\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Cottontail Masse: 0.702 Metabolisme: 220.0 R: 1243.2 RN: 253.4 Erreur R (%): -465.1 Erreur RN (%):-15.2\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Pronghorn Masse: 32.0 Metabolisme: 4320.0 R: 3028.1 RN: 4182.7 Erreur R (%): 29.9 Erreur RN (%):3.2\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Camel Masse: 407.0 Metabolisme: 23600.0 R: 24413.1 RN: 30623.8 Erreur R (%): -3.4 Erreur RN (%):-29.8\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Asian elephant Masse: 3000.0 Metabolisme: 165000.0 R: 172283.6 RN: 166685.4 Erreur R (%): -4.4 Erreur RN (%):-1.0\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Roe deer Masse: 19.0 Metabolisme: 3670.0 R: 2286.7 RN: 2550.6 Erreur R (%): 37.7 Erreur RN (%):30.5\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Red deer Masse: 58.0 Metabolisme: 7800.0 R: 4510.8 RN: 7446.8 Erreur R (%): 42.2 Erreur RN (%):4.5\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom # Horse Masse: 400.0 Metabolisme: 32000.0 R: 24013.9 RN: 30256.5 Erreur R (%): 25.0 Erreur RN (%):5.4\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Merino sheep Masse: 49.0 Metabolisme: 4200.0 R: 3997.5 RN: 6316.9 Erreur R (%): 4.8 Erreur RN (%):-50.4\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Sheep Masse: 65.0 Metabolisme: 10700.0 R: 4909.9 RN: 8268.6 Erreur R (%): 54.1 Erreur RN (%):22.7\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Buffalo Masse: 420.0 Metabolisme: 29400.0 R: 25154.5 RN: 31306.0 Erreur R (%): 14.4 Erreur RN (%):-6.5\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Chamois Masse: 40.0 Metabolisme: 3140.0 R: 3484.3 RN: 5187.0 Erreur R (%): -11.0 Erreur RN (%):-65.2\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Nom Swine Masse: 140.0 Metabolisme: 12000.0 R: 9187.0 RN: 15481.5 Erreur R (%): 23.4 Erreur RN (%):-29.0\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Nom Collored peccary Masse: 20.2 Metabolisme: 826.0 R: 2355.1 RN: 2701.2 Erreur R (%): -185.1 Erreur RN (%):-227.0\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Nom Otter Masse: 10.0 Metabolisme: 2200.0 R: 1773.5 RN: 1420.7 Erreur R (%): 19.4 Erreur RN (%):35.4\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Wolverine Masse: 12.7 Metabolisme: 2820.0 R: 1927.4 RN: 1759.7 Erreur R (%): 31.7 Erreur RN (%):37.6\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Badger Masse: 11.1 Metabolisme: 1440.0 R: 1836.2 RN: 1558.8 Erreur R (%): -27.5 Erreur RN (%):-8.3\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Sea otter Masse: 40.0 Metabolisme: 12400.0 R: 3484.3 RN: 5187.0 Erreur R (%): 71.9 Erreur RN (%):58.2\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Fox Masse: 5.01 Metabolisme: 1210.0 R: 1488.9 RN: 794.2 Erreur R (%): -23.0 Erreur RN (%):34.4\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Nom Coyote Masse: 10.0 Metabolisme: 1320.0 R: 1773.5 RN: 1420.7 Erreur R (%): -34.4 Erreur RN (%):-7.6\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Dog Masse: 14.0 Metabolisme: 1880.0 R: 2001.6 RN: 1922.9 Erreur R (%): -6.5 Erreur RN (%):-2.3\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Jaguar Masse: 18.0 Metabolisme: 2440.0 R: 2229.7 RN: 2425.0 Erreur R (%): 8.6 Erreur RN (%):0.6\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Nom # Cat Masse: 3.0 Metabolisme: 546.0 R: 1374.3 RN: 541.9 Erreur R (%): -151.7 Erreur RN (%):0.8\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Nom Mink Masse: 0.66 Metabolisme: 239.0 R: 1240.8 RN: 248.1 Erreur R (%): -419.2 Erreur RN (%):-3.8\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Harbor seal Masse: 26.0 Metabolisme: 7400.0 R: 2685.9 RN: 3429.4 Erreur R (%): 63.7 Erreur RN (%):53.7\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Beluga whale Masse: 170.0 Metabolisme: 23000.0 R: 10897.8 RN: 18187.8 Erreur R (%): 52.6 Erreur RN (%):20.9\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Bottle-nosed whale Masse: 1000.0 Metabolisme: 69500.0 R: 58230.0 RN: 61740.1 Erreur R (%): 16.2 Erreur RN (%):11.2\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Bat Masse: 0.029 Metabolisme: 9.65 R: 1204.9 RN: 168.9 Erreur R (%): -12386.0 Erreur RN (%):-1650.3\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nom Bat Masse: 0.022 Metabolisme: 15.6 R: 1204.5 RN: 168.0 Erreur R (%): -7621.2 Erreur RN (%):-976.9\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Nom Ghost bat Masse: 0.148 Metabolisme: 68.0 R: 1211.6 RN: 183.8 Erreur R (%): -1681.8 Erreur RN (%):-170.3\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Nom Molossid bat Masse: 0.057 Metabolisme: 14.2 R: 1206.5 RN: 172.4 Erreur R (%): -8396.5 Erreur RN (%):-1114.1\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Fox bat Masse: 0.598 Metabolisme: 153.0 R: 1237.3 RN: 240.3 Erreur R (%): -708.7 Erreur RN (%):-57.1\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nom Chimpanzee Masse: 45.0 Metabolisme: 4620.0 R: 3769.4 RN: 5814.7 Erreur R (%): 18.4 Erreur RN (%):-25.9\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Rhesus monkey Masse: 5.0 Metabolisme: 960.0 R: 1488.3 RN: 793.0 Erreur R (%): -55.0 Erreur RN (%):17.4\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom Orangutan Masse: 150.0 Metabolisme: 15500.0 R: 9757.2 RN: 16386.6 Erreur R (%): 37.1 Erreur RN (%):-5.7\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Nom Gorilla Masse: 250.0 Metabolisme: 21000.0 R: 15459.9 RN: 22385.6 Erreur R (%): 26.4 Erreur RN (%):-6.6\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Nom Gibbon Masse: 8.0 Metabolisme: 1510.0 R: 1659.4 RN: 1169.6 Erreur R (%): -9.9 Erreur RN (%):22.5\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Nom # Man Masse: 65.0 Metabolisme: 7560.0 R: 4909.9 RN: 8268.6 Erreur R (%): 35.1 Erreur RN (%):-9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "df = pd.DataFrame(columns=['Name', 'Age', 'Birth City', 'Gender'])\n",
        "df2 = pd.DataFrame([[\"josée\",3,\"Montréal\",\"femme\"]],columns=['Name', 'Age', 'Birth City', 'Gender'])\n",
        "for i in range(0,10):\n",
        "  df2 = pd.DataFrame([[\"josée\",i,\"Montréal\",\"femme\"]],columns=['Name', 'Age', 'Birth City', 'Gender'])\n",
        "  df=df.append(df2)\n",
        "print(len(df))\n",
        "print(df)\n",
        "'''\n",
        "listeColonnes=['Nom', 'Masse', 'Metabolisme', 'Regression','ReseauN', 'ErreurR', 'ErreurRN']\n",
        "dfinal = pd.DataFrame(columns=listeColonnes)\n",
        "for i in range(0,len(loi_kleiber_data['NomCommun'])):\n",
        "    df2 = pd.DataFrame([[str(loi_kleiber_data['NomCommun'][i]),\n",
        "                         str(loi_kleiber_data['Masse'][i]),\n",
        "                         str(loi_kleiber_data['Metabolisme'][i]),\n",
        "                         str(obtientPredictionDuR(loi_kleiber_data['Masse'][i])),\n",
        "                         str(obtientPredictionDuRN(loi_kleiber_data['Masse'][i])),\n",
        "                         str(calculErreur(loi_kleiber_data['Metabolisme'][i],obtientPredictionDuR(loi_kleiber_data['Masse'][i]))),\n",
        "                         str(calculErreur(loi_kleiber_data['Metabolisme'][i],obtientPredictionDuRN(loi_kleiber_data['Masse'][i])))]], columns=listeColonnes)\n",
        "                             \n",
        "    dfinal=dfinal.append(df2)                 \n",
        "\n",
        "print(dfinal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBpS-R9BBsd7",
        "outputId": "7d842e4e-fc49-480f-91a0-42acfd6c8746"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "                       Nom  Masse Metabolisme Regression  ReseauN ErreurR  \\\n",
            "0                  Echidna    2.5       302.0     1345.8    479.1  -345.6   \n",
            "0      Long-beaked echidna   10.3       594.0     1790.6   1458.4  -201.4   \n",
            "0                 Platypus    1.3       229.0     1277.3    328.5  -457.8   \n",
            "0                  Opossum  0.812       196.0     1249.5    267.2  -537.5   \n",
            "0   South American opossum   1.33       299.0     1279.0    332.2  -327.8   \n",
            "..                     ...    ...         ...        ...      ...     ...   \n",
            "0            Rhesus monkey    5.0       960.0     1488.3    793.0   -55.0   \n",
            "0                Orangutan  150.0     15500.0     9757.2  16386.6    37.1   \n",
            "0                  Gorilla  250.0     21000.0    15459.9  22385.6    26.4   \n",
            "0                   Gibbon    8.0      1510.0     1659.4   1169.6    -9.9   \n",
            "0                    # Man   65.0      7560.0     4909.9   8268.6    35.1   \n",
            "\n",
            "   ErreurRN  \n",
            "0     -58.6  \n",
            "0    -145.5  \n",
            "0     -43.4  \n",
            "0     -36.3  \n",
            "0     -11.1  \n",
            "..      ...  \n",
            "0      17.4  \n",
            "0      -5.7  \n",
            "0      -6.6  \n",
            "0      22.5  \n",
            "0      -9.4  \n",
            "\n",
            "[95 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(\n",
        "    [['Jane', 23, 'London', 'F']], \n",
        "    columns=['Name', 'Age', 'Birth City', 'Gender']\n",
        "    )\n",
        "df = df.append(df2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RH73ESwE12K",
        "outputId": "0667b81d-9eeb-4625-f797-aee2d81424a2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Name Age Birth City Gender\n",
            "0  Jane  23     London      F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obtientPredictionDuRN(masse=400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0pyBE1DiGhe",
        "outputId": "3f7f2d21-b69d-4f27-e2de-a916b202ceb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30256.51"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(listeResultatsRN)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "plt.plot(range(2,3000,20),listeResultatsRN)\n",
        "plt.scatter(loi_kleiber_data['Masse'], loi_kleiber_data['Metabolisme'], color='red')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(2,3000,20),listeResultatsR)\n",
        "plt.scatter(loi_kleiber_data['Masse'], loi_kleiber_data['Metabolisme'], color='red')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "jfJy4JyigKsn",
        "outputId": "b99db599-7365-4bc5-d092-09ce6c78f979"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[416.3, 2927.2, 5438.1, 7948.5, 10082.4, 12042.1, 13852.3, 15662.6, 17472.8, 18817.5, 19866.9, 20916.4, 21965.8, 23015.3, 24064.7, 25114.2, 26163.6, 27213.1, 28262.6, 29312.0, 30361.4, 31410.9, 32460.4, 33509.8, 34559.3, 35608.7, 36658.2, 37707.6, 38757.1, 39806.5, 40856.0, 41905.4, 42954.9, 44004.3, 45053.8, 46103.2, 47152.7, 48202.2, 49251.6, 50301.0, 51350.5, 52400.0, 53449.4, 54498.9, 55548.3, 56597.8, 57647.2, 58696.7, 59746.1, 60795.6, 61845.0, 62894.5, 63943.9, 64993.4, 66042.8, 67092.3, 68141.8, 69191.2, 70240.6, 71290.1, 72339.6, 73389.0, 74438.5, 75487.9, 76537.4, 77586.8, 78636.3, 79685.7, 80735.2, 81784.6, 82834.1, 83883.5, 84933.0, 85982.4, 87031.9, 88081.4, 89130.8, 90180.3, 91229.7, 92279.2, 93328.6, 94378.1, 95427.5, 96477.0, 97526.4, 98575.9, 99625.3, 100674.8, 101724.2, 102773.7, 103823.2, 104872.6, 105922.0, 106971.5, 108021.0, 109070.4, 110119.9, 111169.3, 112218.8, 113268.2, 114317.7, 115367.1, 116416.6, 117466.0, 118515.5, 119564.9, 120614.4, 121663.8, 122713.3, 123762.8, 124812.2, 125861.6, 126911.1, 127960.6, 129010.0, 130059.5, 131108.9, 132158.4, 133207.8, 134257.3, 135306.7, 136356.2, 137405.6, 138455.1, 139504.5, 140554.0, 141603.4, 142652.9, 143702.3, 144751.8, 145801.2, 146850.7, 147900.2, 148949.6, 149999.1, 151048.5, 152098.0, 153147.4, 154196.9, 155246.3, 156295.8, 157345.2, 158394.7, 159444.1, 160493.6, 161543.1, 162592.5, 163642.0, 164691.4, 165740.9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}